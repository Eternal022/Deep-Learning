{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:20.657936Z","iopub.status.busy":"2024-06-16T16:28:20.657564Z","iopub.status.idle":"2024-06-16T16:28:26.990897Z","shell.execute_reply":"2024-06-16T16:28:26.989507Z","shell.execute_reply.started":"2024-06-16T16:28:20.657904Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from copy import deepcopy\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchinfo import summary\n","\n","from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, MultiStepLR, CyclicLR, LambdaLR\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, Normalizer\n","from sklearn.metrics import accuracy_score, roc_auc_score\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. 导入所需数据"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:32.231852Z","iopub.status.busy":"2024-06-16T16:28:32.230184Z","iopub.status.idle":"2024-06-16T16:28:32.555460Z","shell.execute_reply":"2024-06-16T16:28:32.554092Z","shell.execute_reply.started":"2024-06-16T16:28:32.231799Z"},"trusted":true},"outputs":[],"source":["train=pd.read_csv(\"/kaggle/input/playground-series-s4e3/train.csv\")\n","test=pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')\n","sample=pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')\n","original=pd.read_csv('/kaggle/input/faulty-steel-plates/faults.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## 2.结合原始数据和合成数据"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:36.133220Z","iopub.status.busy":"2024-06-16T16:28:36.132725Z","iopub.status.idle":"2024-06-16T16:28:36.158517Z","shell.execute_reply":"2024-06-16T16:28:36.157275Z","shell.execute_reply.started":"2024-06-16T16:28:36.133176Z"},"trusted":true},"outputs":[],"source":["train=pd.concat([train.drop(columns=['id'],axis=1),original],axis=0)\n","train.shape\n","target_cols=train.iloc[:,-7:].columns.tolist()\n","target_cols"]},{"cell_type":"markdown","metadata":{},"source":["## 3.特征工程"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:38.896020Z","iopub.status.busy":"2024-06-16T16:28:38.895106Z","iopub.status.idle":"2024-06-16T16:28:38.910079Z","shell.execute_reply":"2024-06-16T16:28:38.908534Z","shell.execute_reply.started":"2024-06-16T16:28:38.895979Z"},"trusted":true},"outputs":[],"source":["def feat_eng(df):\n","    df[\"X_center\"]= (df[\"X_Minimum\"]+df[\"X_Maximum\"])/2\n","    df[\"Y_center\"]= (df[\"Y_Minimum\"]+df[\"Y_Maximum\"])/2\n","    df[\"elongation_index\"]=(df['Y_Maximum']-df['Y_Minimum'])/abs(((df['X_Maximum']-df['X_Minimum'])+1e-8))\n","    df[\"Rectangularity\"]=df[\"Pixels_Areas\"]/(((df[\"X_Maximum\"] - df[\"X_Minimum\"]) * (df[\"Y_Maximum\"] - df[\"Y_Minimum\"]))+1e-8)\n","    df[\"Normalized X_Center\"]=((df[\"X_Minimum\"]+df[\"X_Maximum\"])/2)/(df[\"Length_of_Conveyer\"]+1e-8)\n","    df[\"Normalized Y_Center\"]=((df[\"Y_Minimum\"]+df[\"Y_Maximum\"])/2)/(df[\"Steel_Plate_Thickness\"]+1e-8)\n","    df[\"Perimeter InteractionA300\"]=(df[\"X_Perimeter\"]/(df[\"Y_Perimeter\"])*df[\"TypeOfSteel_A300\"]+1e-8)\n","    df[\"Perimeter InteractionA400\"]=(df[\"X_Perimeter\"]/(df[\"Y_Perimeter\"])*df[\"TypeOfSteel_A400\"]+1e-8)\n","    df[\"log_XtoY_perimeter\"]=np.log(df[\"X_Perimeter\"]/df[\"Y_Perimeter\"])\n","    df[\"PixelArea_to_Thickness\"]=np.log(df[\"Pixels_Areas\"] / (df[\"Steel_Plate_Thickness\"]+1e-8))\n","    df[\"Normalized Area\"]=df[\"Pixels_Areas\"]/((df[\"Length_of_Conveyer\"]*df[\"Steel_Plate_Thickness\"])+1e-8)\n","    df[\"Luminosity Contrast\"]=(df[\"Maximum_of_Luminosity\"]-df[\"Minimum_of_Luminosity\"])/(df[\"Sum_of_Luminosity\"]+1e-8)\n","    df[\"Density\"]=df[\"Pixels_Areas\"]/(((df[\"X_Maximum\"]-df[\"X_Minimum\"])*(df[\"Y_Maximum\"]-df[\"Y_Minimum\"]))+1e-8)\n","    df[\"Thickness&Luminosity\"]=df[\"Steel_Plate_Thickness\"]* (df[\"Sum_of_Luminosity\"]+1e-8)\n","    df[\"Edge_Density\"]=(df[\"Edges_X_Index\"]+df[\"Edges_Y_Index\"])/(df[\"Pixels_Areas\"]+1e-8)\n","    df['Spatial_Distribution_Index'] = df['Edges_Index']+df['Empty_Index']+df['Square_Index']+df['Outside_X_Index']+df['Edges_X_Index']+df['Edges_Y_Index']+df['Outside_Global_Index']\n","    df['_Color_Range']=df['Maximum_of_Luminosity']-df['Minimum_of_Luminosity']\n","    df['_Compactness_X']=df['Pixels_Areas']/(df['X_Perimeter']**2)\n","    df['_Compactness_Y']=df['Pixels_Areas']/(df['Y_Perimeter']**2)\n","    df['_Normalized_Luminosity_Index'] = df['Luminosity_Index'] / (df['Pixels_Areas']+1e-8)\n","    df['_Thickness_Steel_Type'] = df['Steel_Plate_Thickness']*(df['TypeOfSteel_A300']+df['TypeOfSteel_A400'])\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:45.335125Z","iopub.status.busy":"2024-06-16T16:28:45.334647Z","iopub.status.idle":"2024-06-16T16:28:45.412981Z","shell.execute_reply":"2024-06-16T16:28:45.411868Z","shell.execute_reply.started":"2024-06-16T16:28:45.335085Z"},"trusted":true},"outputs":[],"source":["feat_eng(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:48.917979Z","iopub.status.busy":"2024-06-16T16:28:48.917606Z","iopub.status.idle":"2024-06-16T16:28:48.971403Z","shell.execute_reply":"2024-06-16T16:28:48.969955Z","shell.execute_reply.started":"2024-06-16T16:28:48.917950Z"},"trusted":true},"outputs":[],"source":["feat_eng(test)"]},{"cell_type":"markdown","metadata":{},"source":["## 4.分割目标与特征"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:28:53.942710Z","iopub.status.busy":"2024-06-16T16:28:53.942305Z","iopub.status.idle":"2024-06-16T16:28:53.962592Z","shell.execute_reply":"2024-06-16T16:28:53.961085Z","shell.execute_reply.started":"2024-06-16T16:28:53.942677Z"},"trusted":true},"outputs":[],"source":["X=train.drop(columns=target_cols,axis=1)\n","y=train.loc[:,target_cols]\n","X.head()\n","y.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 5. 创建DataLoader"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:29:00.295981Z","iopub.status.busy":"2024-06-16T16:29:00.295502Z","iopub.status.idle":"2024-06-16T16:29:00.404235Z","shell.execute_reply":"2024-06-16T16:29:00.402818Z","shell.execute_reply.started":"2024-06-16T16:29:00.295940Z"},"trusted":true},"outputs":[],"source":["# 将数据集分割为训练集和验证集，测试集比例为20%\n","X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=17)\n","\n","# 标准化数据\n","std_scaler=StandardScaler()\n","X_train_scaled=std_scaler.fit_transform(X_train)\n","X_val_scaled=std_scaler.transform(X_val)\n","\n","# 创建张量\n","X_train_tensor,y_train_tensor=torch.as_tensor(X_train_scaled,dtype=torch.float32),torch.as_tensor(y_train.values,dtype=torch.float32)\n","X_val_tensor,y_val_tensor=torch.as_tensor(X_val_scaled,dtype=torch.float32),torch.as_tensor(y_val.values,dtype=torch.float32)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 6. 创建自定义数据类"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:29:03.049729Z","iopub.status.busy":"2024-06-16T16:29:03.049225Z","iopub.status.idle":"2024-06-16T16:29:03.058253Z","shell.execute_reply":"2024-06-16T16:29:03.056653Z","shell.execute_reply.started":"2024-06-16T16:29:03.049688Z"},"trusted":true},"outputs":[],"source":["class TabularData(Dataset):\n","    def __init__(self,x_tensor,y_tensor):\n","        self.x=x_tensor\n","        self.y=y_tensor\n","\n","    def __getitem__(self, index):\n","        return (self.x[index],self.y[index])\n","    \n","    def __len__(self):\n","        return len(self.x)\n","\n","        "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:29:05.841604Z","iopub.status.busy":"2024-06-16T16:29:05.840400Z","iopub.status.idle":"2024-06-16T16:29:05.851031Z","shell.execute_reply":"2024-06-16T16:29:05.849248Z","shell.execute_reply.started":"2024-06-16T16:29:05.841556Z"},"trusted":true},"outputs":[],"source":["train_dataset=TabularData(X_train_tensor,y_train_tensor)\n","val_dataset=TabularData(X_val_tensor,y_val_tensor)\n","\n","train_loader=DataLoader(train_dataset,batch_size=256,num_workers=4,pin_memory=True,shuffle=True)\n","val_loader=DataLoader(val_dataset,batch_size=256,num_workers=4,pin_memory=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 7. 创建模型训练类"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:29:10.669254Z","iopub.status.busy":"2024-06-16T16:29:10.668837Z","iopub.status.idle":"2024-06-16T16:29:10.697285Z","shell.execute_reply":"2024-06-16T16:29:10.695852Z","shell.execute_reply.started":"2024-06-16T16:29:10.669219Z"},"trusted":true},"outputs":[],"source":["class AllShitsHere(object):\n","    def __init__(self, model, loss_fn, optimizer, es_patience=5):\n","        # 初始化参数\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","        self.model.to(self.device)\n","\n","        # 初始化将来使用的变量（目前为空）\n","        self.train_loader = None\n","        self.val_loader = None\n","\n","        # 用于早停的参数\n","        self.patience = es_patience\n","        self.min_delta = 0\n","        self.counter = 0\n","        self.min_validation_loss = float('inf')\n","\n","        # 内部计算\n","        self.losses = []\n","        self.val_losses = []\n","        self.total_epochs = 0\n","        self.scores = []\n","        self.val_scores = []\n","\n","        # 训练和验证步骤函数\n","        self.train_step_fn = self._make_train_step_fn()\n","        self.val_step_fn = self._make_val_step_fn()\n","\n","    def _should_early_stop(self, val_loss):\n","        if val_loss < self.min_validation_loss:\n","            self.min_validation_loss = val_loss\n","            counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False\n","\n","    def to(self, device):\n","        try:\n","            self.device = device\n","            self.model.to(self.device)\n","        except RuntimeError:\n","            self.device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n","            print(f\"Can't send to {device}, moving to {self.device} instead!\")\n","            self.model.to(self.device)\n","\n","    def set_loaders(self, train_loader, val_loader=None):\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","\n","    def calculate_scores(self, yhat, y):\n","        scores_per_epoch = []\n","        for i in range(7):\n","            try:\n","                score = roc_auc_score(y[:, i].detach().cpu().numpy(), yhat[:, i].detach().cpu().numpy(),\n","                                      multi_class='ovo', average='weighted')\n","                scores_per_epoch.append(score)\n","            except ValueError:\n","                scores_per_epoch.append(0.5)\n","        return np.mean(scores_per_epoch)\n","\n","    def _make_train_step_fn(self):\n","        def perform_train_step_fn(X, y):\n","            # 设置模型为训练模式\n","            self.model.train()\n","            # 前向传播\n","            yhat = self.model(X)\n","            # 计算得分\n","            train_score = self.calculate_scores(yhat, y)\n","            # 计算损失\n","            loss = self.loss_fn(yhat, y)\n","            # 计算梯度\n","            loss.backward()\n","            # 更新参数\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","            return loss.item(), train_score\n","\n","        return perform_train_step_fn\n","\n","    def _make_val_step_fn(self):\n","        def perform_val_step(X, y):\n","            # 设置模型为评估模式\n","            self.model.eval()\n","            # 前向传播\n","            yhat = self.model(X)\n","            # 计算得分\n","            val_score = self.calculate_scores(yhat, y)\n","            # 计算损失\n","            loss = self.loss_fn(yhat, y)\n","\n","            return loss.item(), val_score\n","\n","        return perform_val_step\n","\n","    def _mini_batch(self, validation=False):\n","        if validation:\n","            data_loader = self.val_loader\n","            step_fn = self.val_step_fn\n","\n","        else:\n","            data_loader = self.train_loader\n","            step_fn = self.train_step_fn\n","\n","        if data_loader is None:\n","            return None\n","\n","        mini_batch_losses = []\n","        mini_batch_scores = []\n","        for X_batch, y_batch in data_loader:\n","            X_batch = X_batch.to(self.device)\n","            y_batch = y_batch.to(self.device)\n","\n","            mini_batch_loss, mini_batch_score = step_fn(X_batch, y_batch)\n","            mini_batch_losses.append(mini_batch_loss)\n","            mini_batch_scores.append(mini_batch_score)\n","\n","        return np.mean(mini_batch_losses), np.mean(mini_batch_scores)\n","\n","    def set_seed(self, seed=42):\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","\n","    def train(self, n_epochs, seed=42):\n","        self.set_seed(seed)\n","        for epoch in tqdm(range(n_epochs)):\n","            self.total_epochs += 1\n","            # 使用小批量进行训练\n","            loss, train_score = self._mini_batch(validation=False)\n","            self.scores.append(train_score)\n","            self.losses.append(loss)\n","\n","            # 使用小批量进行验证\n","            with torch.no_grad():\n","                val_loss, val_score = self._mini_batch(validation=True)\n","                self.val_losses.append(val_loss)\n","                self.val_scores.append(val_score)\n","                if self._should_early_stop(val_loss):\n","                    print(\"early stopping\")\n","                    break\n","\n","    def predict(self, X):\n","        self.model.eval()\n","        X_tensor = torch.as_tensor(X, dtype=torch.float32, device=self.device)\n","        self.model.train()\n","        yhat_tensor = self.model(X_tensor)\n","        return yhat_tensor.detach().cpu().numpy()\n","\n","    def plot_figures(self):\n","        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n","        axes[0].plot(self.losses, label='training loss', c='b')\n","        axes[0].plot(self.val_losses, label='validation loss', c='r')\n","        axes[0].set_xlabel(\"Epochs\")\n","        axes[0].set_ylabel(\"Losses\")\n","\n","        axes[1].plot(self.scores, label='training score', c='b')\n","        axes[1].plot(self.val_scores, label='validation score', c='r')\n","        axes[1].set_xlabel(\"Epochs\")\n","        axes[1].set_ylabel(\"AUC-ROC\")\n","\n","        axes[0].legend()\n","        axes[1].legend()\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 8.创建模型类"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:29:15.366531Z","iopub.status.busy":"2024-06-16T16:29:15.366041Z","iopub.status.idle":"2024-06-16T16:29:15.377819Z","shell.execute_reply":"2024-06-16T16:29:15.376140Z","shell.execute_reply.started":"2024-06-16T16:29:15.366491Z"},"trusted":true},"outputs":[],"source":["class TabularNet(nn.Module):\n","    def __init__(self,p,input_shape,output_shape):\n","        super(TabularNet,self).__init__()\n","        self.p=p\n","        self.input_shape=input_shape\n","        self.output_shape=output_shape\n","\n","        self.feature_extractor=nn.Sequential(\n","            nn.Linear(input_shape,384),\n","            nn.BatchNorm1d(384),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(384,1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(1024,128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(64,32),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.Dropout(self.p))\n","        \n","        self.classifier=nn.Sequential(\n","            nn.Linear(32,output_shape),\n","            nn.Sigmoid())\n","        \n","    def forward(self,x):\n","        x=self.feature_extractor(x)\n","        x=self.classifier(x)\n","        return x\n","        \n","        \n","        \n","          "]},{"cell_type":"markdown","metadata":{},"source":["## 9.模型训练"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:37:21.766803Z","iopub.status.busy":"2024-06-16T16:37:21.764907Z","iopub.status.idle":"2024-06-16T16:37:21.803656Z","shell.execute_reply":"2024-06-16T16:37:21.802260Z","shell.execute_reply.started":"2024-06-16T16:37:21.766731Z"},"trusted":true},"outputs":[],"source":["model=TabularNet(p=0.3,input_shape=48,output_shape=7)\n","optimizer=optim.Adam(model.parameters(),lr=0.001)\n","loss_fn=nn.BCELoss(reduction='mean')\n","\n","summary(model,input_size=(256,48))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:39:31.687721Z","iopub.status.busy":"2024-06-16T16:39:31.687249Z","iopub.status.idle":"2024-06-16T16:39:31.697242Z","shell.execute_reply":"2024-06-16T16:39:31.695403Z","shell.execute_reply.started":"2024-06-16T16:39:31.687690Z"},"trusted":true},"outputs":[],"source":["AnuwazNet=AllShitsHere(model,loss_fn,optimizer)\n","AnuwazNet.set_loaders(train_loader,val_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T16:39:35.193104Z","iopub.status.busy":"2024-06-16T16:39:35.192637Z","iopub.status.idle":"2024-06-16T16:39:42.768425Z","shell.execute_reply":"2024-06-16T16:39:42.766429Z","shell.execute_reply.started":"2024-06-16T16:39:35.193068Z"},"trusted":true},"outputs":[],"source":["AnuwazNet.train(100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["AnuwazNet.plot_figures()\n","AnuwazNet.val_scores\n","AnuwazNet.val_losses.index(min(AnuwazNet.val_losses))"]},{"cell_type":"markdown","metadata":{},"source":["## 10. 预测"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:06:29.582298Z","iopub.status.busy":"2024-03-09T11:06:29.581461Z","iopub.status.idle":"2024-03-09T11:06:29.61857Z","shell.execute_reply":"2024-03-09T11:06:29.617739Z","shell.execute_reply.started":"2024-03-09T11:06:29.582241Z"},"trusted":true},"outputs":[],"source":["preds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\n","for i,col in enumerate(target_cols):\n","    sample[col]=preds[:,i]\n","\n","sample.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 11.开始制作原型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:06:29.79124Z","iopub.status.busy":"2024-03-09T11:06:29.790896Z","iopub.status.idle":"2024-03-09T11:06:29.799543Z","shell.execute_reply":"2024-03-09T11:06:29.798588Z","shell.execute_reply.started":"2024-03-09T11:06:29.791201Z"},"trusted":true},"outputs":[],"source":["def make_data_loader(X_train,X_val,y_train,y_val):\n","\n","    # 标准化数据\n","    std_scaler=StandardScaler()\n","    X_train_scaled=std_scaler.fit_transform(X_train)\n","    X_val_scaled=std_scaler.transform(X_val)\n","\n","     # 创建张量\n","    X_train_tensor,y_train_tensor=torch.as_tensor(X_train_scaled,dtype=torch.float32),torch.as_tensor(y_train.values,dtype=torch.float32)\n","    X_val_tensor,y_val_tensor=torch.as_tensor(X_val_scaled,dtype=torch.float32),torch.as_tensor(y_val.values,dtype=torch.float32)\n","\n","    train_dataset=TabularData(X_train_tensor,y_train_tensor)\n","    val_dataset=TabularData(X_val_tensor,y_val_tensor)\n","\n","    train_loader=DataLoader(train_dataset,batch_size=256,num_workers=4,pin_memory=True,shuffle=True)\n","    val_loader=DataLoader(val_dataset,batch_size=256,num_workers=4,pin_memory=True)\n","\n","    return train_loader,val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:06:41.866533Z","iopub.status.busy":"2024-03-09T11:06:41.866214Z","iopub.status.idle":"2024-03-09T11:09:00.675703Z","shell.execute_reply":"2024-03-09T11:09:00.674656Z","shell.execute_reply.started":"2024-03-09T11:06:41.866505Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","mskf=MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n","\n","all_predictions=[]\n","final_mean_scores=[]\n","# 执行交叉验证\n","for train_idx, val_idx in mskf.split(X,y):\n","    X_train,y_train=X.iloc[train_idx],y.iloc[train_idx]\n","    X_val,y_val=X.iloc[val_idx],y.iloc[val_idx]\n","\n","    train_loader,val_loader=make_data_loader(X_train,X_val,y_train,y_val)\n","\n","    model=TabularNet(p=0.3,input_shape=48,output_shape=7)\n","    optimizer=optim.Adam(model.parameters(),lr=3e-4)\n","    loss_fn=nn.BCELoss(reduction='mean')\n","\n","    AnuwazNet=AllShitsHere(model,loss_fn,optimizer)\n","    AnuwazNet.set_loaders(train_loader,val_loader)\n","    AnuwazNet.train(100)\n","    print(f\"Min val loss: {np.min(AnuwazNet.val_losses)}\\tFinal val loss: {np.mean(AnuwazNet.val_losses)}\")\n","    preds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\n","    all_predictions.append(preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:00.677723Z","iopub.status.busy":"2024-03-09T11:09:00.677396Z","iopub.status.idle":"2024-03-09T11:09:00.683539Z","shell.execute_reply":"2024-03-09T11:09:00.68247Z","shell.execute_reply.started":"2024-03-09T11:09:00.677686Z"},"trusted":true},"outputs":[],"source":["def output(pred_list):\n","    pred_array=np.array(pred_list)\n","    pred_array_mean=np.mean(pred_array,axis=0)\n","\n","    for i,col in enumerate(target_cols):\n","        sample[col]=pred_array_mean[:,i]\n","\n","    return sample\n","output(all_predictions)"]},{"cell_type":"markdown","metadata":{},"source":["## 12.优化类"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:00.719125Z","iopub.status.busy":"2024-03-09T11:09:00.718877Z","iopub.status.idle":"2024-03-09T11:09:00.745703Z","shell.execute_reply":"2024-03-09T11:09:00.744939Z","shell.execute_reply.started":"2024-03-09T11:09:00.719103Z"},"trusted":true},"outputs":[],"source":["class Goodclass(object):\n","    def __init__(self, model, loss_fn, optimizer, es_patience=5):\n","        # 初始化参数\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","        self.model.to(self.device)\n","\n","        # 初始化将来使用的变量（目前为空）\n","        self.train_loader = None\n","        self.val_loader = None\n","\n","        # 用于早停的参数\n","        self.patience = es_patience\n","        self.min_delta = 0\n","        self.counter = 0\n","        self.min_validation_loss = float('inf')\n","\n","        # 内部计算\n","        self.losses = []\n","        self.val_losses = []\n","        self.total_epochs = 0\n","\n","        # 训练和验证步骤函数\n","        self.train_step_fn = self._make_train_step_fn()\n","        self.val_step_fn = self._make_val_step_fn()\n","\n","    def _should_early_stop(self, val_loss):\n","        if val_loss < self.min_validation_loss:\n","            self.min_validation_loss = val_loss\n","            counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False\n","\n","    def to(self, device):\n","        try:\n","            self.device = device\n","            self.model.to(self.device)\n","        except RuntimeError:\n","            self.device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n","            print(f\"Can't send to {device}, moving to {self.device} instead!\")\n","            self.model.to(self.device)\n","\n","    def set_loaders(self, train_loader, val_loader=None):\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","\n","    def _make_train_step_fn(self):\n","        def perform_train_step_fn(X, y):\n","            # 设置模型为训练模式\n","            self.model.train()\n","            # 前向传播\n","            yhat = self.model(X)\n","            # 计算损失\n","            loss = self.loss_fn(yhat, y)\n","            # 计算梯度\n","            loss.backward()\n","            # 更新参数\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","            return loss.item()\n","\n","        return perform_train_step_fn\n","\n","    def _make_val_step_fn(self):\n","        def perform_val_step(X, y):\n","            # 设置模型为评估模式\n","            self.model.eval()\n","            # 前向传播\n","            yhat = self.model(X)\n","            # 计算损失\n","            loss = self.loss_fn(yhat, y)\n","\n","            return loss.item()\n","\n","        return perform_val_step\n","\n","    def _mini_batch(self, validation=False):\n","        if validation:\n","            data_loader = self.val_loader\n","            step_fn = self.val_step_fn\n","\n","        else:\n","            data_loader = self.train_loader\n","            step_fn = self.train_step_fn\n","\n","        if data_loader is None:\n","            return None\n","\n","        mini_batch_losses = []\n","        mini_batch_scores = []\n","        for X_batch, y_batch in data_loader:\n","            X_batch = X_batch.to(self.device)\n","            y_batch = y_batch.to(self.device)\n","\n","            mini_batch_loss = step_fn(X_batch, y_batch)\n","            mini_batch_losses.append(mini_batch_loss)\n","\n","        return np.mean(mini_batch_losses)\n","\n","    def set_seed(self, seed=42):\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","\n","    def train(self, n_epochs, seed=42):\n","        self.set_seed(seed)\n","        for epoch in tqdm(range(n_epochs)):\n","            self.total_epochs += 1\n","            # 使用小批量进行训练\n","            loss = self._mini_batch(validation=False)\n","            self.losses.append(loss)\n","\n","            # 使用小批量进行验证\n","            with torch.no_grad():\n","                val_loss = self._mini_batch(validation=True)\n","                self.val_losses.append(val_loss)\n","                if self._should_early_stop(val_loss):\n","                    print(\"early stopping\")\n","                    break\n","\n","    def predict(self, X):\n","        self.model.eval()\n","        X_tensor = torch.as_tensor(X, dtype=torch.float32, device=self.device)\n","        yhat_tensor = self.model(X_tensor)\n","        self.model.train()\n","        return yhat_tensor.detach().cpu().numpy()\n","\n","    def plot_figures(self):\n","        fig, ax = plt.subplots(figsize=(10, 4))\n","        ax.plot(self.losses, label='training loss', c='b')\n","        ax.plot(self.val_losses, label='validation loss', c='r')\n","        ax.set_xlabel(\"Epochs\")\n","        ax.set_ylabel(\"Losses\")\n","        ax.legend()\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:00.746943Z","iopub.status.busy":"2024-03-09T11:09:00.746675Z","iopub.status.idle":"2024-03-09T11:09:00.767028Z","shell.execute_reply":"2024-03-09T11:09:00.766301Z","shell.execute_reply.started":"2024-03-09T11:09:00.74692Z"},"trusted":true},"outputs":[],"source":["model=TabularNet(p=0.3,input_shape=48,output_shape=7)\n","optimizer=optim.Adam(model.parameters(),lr=0.001)\n","loss_fn=nn.BCELoss(reduction='mean')\n","AnuwazNet=Goodclass(model,loss_fn,optimizer)\n","AnuwazNet.set_loaders(train_loader,val_loader)\n","AnuwazNet.train(100)\n","AnuwazNet.val_losses\n","AnuwazNet.plot_figures()\n","preds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\n","\n","def output_single(preds):\n","\n","    for i,col in enumerate(target_cols):\n","        sample[col]=preds[:,i]\n","\n","    return sample\n","\n","output_single(preds)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 13.找到LR范围\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:29.706642Z","iopub.status.busy":"2024-03-09T11:09:29.706325Z","iopub.status.idle":"2024-03-09T11:09:31.121327Z","shell.execute_reply":"2024-03-09T11:09:31.120477Z","shell.execute_reply.started":"2024-03-09T11:09:29.706612Z"},"trusted":true},"outputs":[],"source":["from torch_lr_finder import LRFinder\n","torch.manual_seed(11)\n","model=TabularNet(p=0.3,input_shape=48,output_shape=7)\n","optimizer=optim.Adam(model.parameters(),lr=3e-4)\n","loss_fn=nn.BCELoss(reduction='mean')\n","device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","lr_finder=LRFinder(model,optimizer,loss_fn,device)\n","lr_finder.range_test(train_loader,end_lr=0.1,num_iter=100)\n","lr_finder.plot(log_lr=True)\n","lr_finder.reset()"]},{"cell_type":"markdown","metadata":{},"source":["## 14.创建更深层模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:31.123455Z","iopub.status.busy":"2024-03-09T11:09:31.123042Z","iopub.status.idle":"2024-03-09T11:09:31.1346Z","shell.execute_reply":"2024-03-09T11:09:31.133599Z","shell.execute_reply.started":"2024-03-09T11:09:31.123401Z"},"trusted":true},"outputs":[],"source":["class TabularNetDeep(nn.Module):\n","    def __init__(self,p,input_shape,output_shape):\n","        super(TabularNetDeep,self).__init__()\n","        self.p=p\n","        self.input_shape=input_shape\n","        self.output_shape=output_shape\n","\n","        self.feature_extractor=nn.Sequential(\n","            nn.Linear(input_shape,512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(512,1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(1024,4096),\n","            nn.BatchNorm1d(4096),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(4096,1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(1024,256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(256,64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Dropout(self.p),\n","            \n","            nn.Linear(64,48),\n","            nn.BatchNorm1d(48),\n","            nn.ReLU(),\n","            nn.Dropout(self.p))\n","        \n","        self.classifier=nn.Sequential(\n","            nn.Linear(48,output_shape),\n","            nn.Sigmoid())\n","        \n","    def forward(self,x):\n","        x=self.feature_extractor(x)\n","        x=self.classifier(x)\n","        return x\n","        \n","        \n","        \n","          "]},{"cell_type":"markdown","metadata":{},"source":["## 15.OOF预测"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T11:09:31.136695Z","iopub.status.busy":"2024-03-09T11:09:31.135972Z","iopub.status.idle":"2024-03-09T11:09:31.14578Z","shell.execute_reply":"2024-03-09T11:09:31.145014Z","shell.execute_reply.started":"2024-03-09T11:09:31.136669Z"},"trusted":true},"outputs":[],"source":["mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","\n","def mean_loss():\n","    mean_val_losses = []\n","    oof_preds = []\n","    # 执行交叉验证\n","    for train_idx, val_idx in mskf.split(X, y):\n","        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n","        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n","\n","        train_loader, val_loader = make_data_loader(X_train, X_val, y_train, y_val)\n","        model = TabularNetDeep(p=0.3, input_shape=48, output_shape=7)\n","        optimizer = optim.Adam(model.parameters(), lr=1.01e-2)\n","        scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n","        loss_fn = nn.BCELoss(reduction='mean')\n","\n","        AnuwazNet = Goodclass(model, loss_fn, optimizer, es_patience=20)\n","        AnuwazNet.set_loaders(train_loader, val_loader)\n","        AnuwazNet.train(100)\n","        print(f\"Min val loss: {np.min(AnuwazNet.val_losses)}\\tFinal val loss: {AnuwazNet.val_losses[-1]}\")\n","        mean_val_losses.append(AnuwazNet.val_losses[-3:])\n","        oof_preds.append(AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id']))))\n","\n","    return np.mean(mean_val_losses), oof_preds\n","\n","mean_validation_losses,oof_predictions=mean_loss()\n","mean_validation_losses\n","def output_single(preds):\n","    preds_arr=np.array(preds)\n","    preds_arr_mean=np.mean(preds_arr,axis=0)\n","    for i,col in enumerate(target_cols):\n","        sample[col]=preds_arr_mean[:,i]\n","\n","    return sample\n","\n","output_single(oof_predictions)\n","output_single(oof_predictions).to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7659021,"sourceId":68699,"sourceType":"competition"},{"datasetId":2363,"sourceId":3972,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
