{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68699,"databundleVersionId":7659021,"sourceType":"competition"},{"sourceId":3972,"sourceType":"datasetVersion","datasetId":2363}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport datetime\nimport random\nimport numpy as np\nimport pandas as pd\nfrom copy import deepcopy\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchinfo import summary\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, MultiStepLR, CyclicLR, LambdaLR\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, Normalizer\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:20.657564Z","iopub.execute_input":"2024-06-16T16:28:20.657936Z","iopub.status.idle":"2024-06-16T16:28:26.990897Z","shell.execute_reply.started":"2024-06-16T16:28:20.657904Z","shell.execute_reply":"2024-06-16T16:28:26.989507Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 1. 导入所需数据","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/playground-series-s4e3/train.csv\")\ntest=pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')\nsample=pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')\noriginal=pd.read_csv('/kaggle/input/faulty-steel-plates/faults.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:32.230184Z","iopub.execute_input":"2024-06-16T16:28:32.231852Z","iopub.status.idle":"2024-06-16T16:28:32.555460Z","shell.execute_reply.started":"2024-06-16T16:28:32.231799Z","shell.execute_reply":"2024-06-16T16:28:32.554092Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 2.结合原始数据和合成数据","metadata":{}},{"cell_type":"code","source":"train=pd.concat([train.drop(columns=['id'],axis=1),original],axis=0)\ntrain.shape\ntarget_cols=train.iloc[:,-7:].columns.tolist()\ntarget_cols","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:36.132725Z","iopub.execute_input":"2024-06-16T16:28:36.133220Z","iopub.status.idle":"2024-06-16T16:28:36.158517Z","shell.execute_reply.started":"2024-06-16T16:28:36.133176Z","shell.execute_reply":"2024-06-16T16:28:36.157275Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['Pastry',\n 'Z_Scratch',\n 'K_Scatch',\n 'Stains',\n 'Dirtiness',\n 'Bumps',\n 'Other_Faults']"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.特征工程","metadata":{}},{"cell_type":"code","source":"def feat_eng(df):\n    df[\"X_center\"]= (df[\"X_Minimum\"]+df[\"X_Maximum\"])/2\n    df[\"Y_center\"]= (df[\"Y_Minimum\"]+df[\"Y_Maximum\"])/2\n    df[\"elongation_index\"]=(df['Y_Maximum']-df['Y_Minimum'])/abs(((df['X_Maximum']-df['X_Minimum'])+1e-8))\n    df[\"Rectangularity\"]=df[\"Pixels_Areas\"]/(((df[\"X_Maximum\"] - df[\"X_Minimum\"]) * (df[\"Y_Maximum\"] - df[\"Y_Minimum\"]))+1e-8)\n    df[\"Normalized X_Center\"]=((df[\"X_Minimum\"]+df[\"X_Maximum\"])/2)/(df[\"Length_of_Conveyer\"]+1e-8)\n    df[\"Normalized Y_Center\"]=((df[\"Y_Minimum\"]+df[\"Y_Maximum\"])/2)/(df[\"Steel_Plate_Thickness\"]+1e-8)\n    df[\"Perimeter InteractionA300\"]=(df[\"X_Perimeter\"]/(df[\"Y_Perimeter\"])*df[\"TypeOfSteel_A300\"]+1e-8)\n    df[\"Perimeter InteractionA400\"]=(df[\"X_Perimeter\"]/(df[\"Y_Perimeter\"])*df[\"TypeOfSteel_A400\"]+1e-8)\n    df[\"log_XtoY_perimeter\"]=np.log(df[\"X_Perimeter\"]/df[\"Y_Perimeter\"])\n    df[\"PixelArea_to_Thickness\"]=np.log(df[\"Pixels_Areas\"] / (df[\"Steel_Plate_Thickness\"]+1e-8))\n    df[\"Normalized Area\"]=df[\"Pixels_Areas\"]/((df[\"Length_of_Conveyer\"]*df[\"Steel_Plate_Thickness\"])+1e-8)\n    df[\"Luminosity Contrast\"]=(df[\"Maximum_of_Luminosity\"]-df[\"Minimum_of_Luminosity\"])/(df[\"Sum_of_Luminosity\"]+1e-8)\n    df[\"Density\"]=df[\"Pixels_Areas\"]/(((df[\"X_Maximum\"]-df[\"X_Minimum\"])*(df[\"Y_Maximum\"]-df[\"Y_Minimum\"]))+1e-8)\n    df[\"Thickness&Luminosity\"]=df[\"Steel_Plate_Thickness\"]* (df[\"Sum_of_Luminosity\"]+1e-8)\n    df[\"Edge_Density\"]=(df[\"Edges_X_Index\"]+df[\"Edges_Y_Index\"])/(df[\"Pixels_Areas\"]+1e-8)\n    df['Spatial_Distribution_Index'] = df['Edges_Index']+df['Empty_Index']+df['Square_Index']+df['Outside_X_Index']+df['Edges_X_Index']+df['Edges_Y_Index']+df['Outside_Global_Index']\n    df['_Color_Range']=df['Maximum_of_Luminosity']-df['Minimum_of_Luminosity']\n    df['_Compactness_X']=df['Pixels_Areas']/(df['X_Perimeter']**2)\n    df['_Compactness_Y']=df['Pixels_Areas']/(df['Y_Perimeter']**2)\n    df['_Normalized_Luminosity_Index'] = df['Luminosity_Index'] / (df['Pixels_Areas']+1e-8)\n    df['_Thickness_Steel_Type'] = df['Steel_Plate_Thickness']*(df['TypeOfSteel_A300']+df['TypeOfSteel_A400'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:38.895106Z","iopub.execute_input":"2024-06-16T16:28:38.896020Z","iopub.status.idle":"2024-06-16T16:28:38.910079Z","shell.execute_reply.started":"2024-06-16T16:28:38.895979Z","shell.execute_reply":"2024-06-16T16:28:38.908534Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"feat_eng(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:45.334647Z","iopub.execute_input":"2024-06-16T16:28:45.335125Z","iopub.status.idle":"2024-06-16T16:28:45.412981Z","shell.execute_reply.started":"2024-06-16T16:28:45.335085Z","shell.execute_reply":"2024-06-16T16:28:45.411868Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n0           584        590     909972     909977            16            8   \n1           808        816     728350     728372           433           20   \n2            39        192    2212076    2212144         11388          705   \n3           781        789    3353146    3353173           210           16   \n4          1540       1560     618457     618502           521           72   \n...         ...        ...        ...        ...           ...          ...   \n1936        249        277     325780     325796           273           54   \n1937        144        175     340581     340598           287           44   \n1938        145        174     386779     386794           292           40   \n1939        137        170     422497     422528           419           97   \n1940       1261       1281      87951      87967           103           26   \n\n      Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n0               5               2274                    113   \n1              54              44478                     70   \n2             420            1311391                     29   \n3              29               3202                    114   \n4              67              48231                     82   \n...           ...                ...                    ...   \n1936           22              35033                    119   \n1937           24              34599                    112   \n1938           22              37572                    120   \n1939           47              52715                    117   \n1940           22              11682                    101   \n\n      Maximum_of_Luminosity  ...  Luminosity Contrast   Density  \\\n0                       140  ...             0.011873  0.533333   \n1                       111  ...             0.000922  2.460227   \n2                       141  ...             0.000085  1.094579   \n3                       134  ...             0.006246  0.972222   \n4                       111  ...             0.000601  0.578889   \n...                     ...  ...                  ...       ...   \n1936                    141  ...             0.000628  0.609375   \n1937                    133  ...             0.000607  0.544592   \n1938                    140  ...             0.000532  0.671264   \n1939                    140  ...             0.000436  0.409580   \n1940                    133  ...             0.002739  0.321875   \n\n      Thickness&Luminosity  Edge_Density  Spatial_Distribution_Index  \\\n0             1.137000e+05      0.125000                      3.6452   \n1             3.558240e+06      0.002887                      3.5775   \n2             5.245564e+07      0.000055                      2.3031   \n3             1.280800e+05      0.006219                      3.6972   \n4             1.446930e+07      0.002297                      2.9558   \n...                    ...           ...                         ...   \n1936          1.401320e+06      0.004563                      2.5946   \n1937          1.383960e+06      0.004923                      2.6513   \n1938          1.502880e+06      0.004818                      2.4872   \n1939          2.108600e+06      0.002386                      2.7554   \n1940          9.345600e+05      0.014529                      3.1055   \n\n      _Color_Range  _Compactness_X  _Compactness_Y  \\\n0               27        0.250000        0.640000   \n1               41        1.082500        0.148491   \n2              112        0.022912        0.064558   \n3               20        0.820312        0.249703   \n4               29        0.100502        0.116061   \n...            ...             ...             ...   \n1936            22        0.093621        0.564050   \n1937            21        0.148244        0.498264   \n1938            20        0.182500        0.603306   \n1939            23        0.044532        0.189679   \n1940            32        0.152367        0.212810   \n\n      _Normalized_Luminosity_Index  _Thickness_Steel_Type  \n0                        -0.000650                     50  \n1                        -0.000692                     80  \n2                        -0.000008                     40  \n3                        -0.000191                     40  \n4                        -0.000471                    300  \n...                            ...                    ...  \n1936                      0.000010                     40  \n1937                     -0.000203                     40  \n1938                      0.000018                     40  \n1939                     -0.000041                     40  \n1940                     -0.001106                     80  \n\n[21160 rows x 55 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_Minimum</th>\n      <th>X_Maximum</th>\n      <th>Y_Minimum</th>\n      <th>Y_Maximum</th>\n      <th>Pixels_Areas</th>\n      <th>X_Perimeter</th>\n      <th>Y_Perimeter</th>\n      <th>Sum_of_Luminosity</th>\n      <th>Minimum_of_Luminosity</th>\n      <th>Maximum_of_Luminosity</th>\n      <th>...</th>\n      <th>Luminosity Contrast</th>\n      <th>Density</th>\n      <th>Thickness&amp;Luminosity</th>\n      <th>Edge_Density</th>\n      <th>Spatial_Distribution_Index</th>\n      <th>_Color_Range</th>\n      <th>_Compactness_X</th>\n      <th>_Compactness_Y</th>\n      <th>_Normalized_Luminosity_Index</th>\n      <th>_Thickness_Steel_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>584</td>\n      <td>590</td>\n      <td>909972</td>\n      <td>909977</td>\n      <td>16</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2274</td>\n      <td>113</td>\n      <td>140</td>\n      <td>...</td>\n      <td>0.011873</td>\n      <td>0.533333</td>\n      <td>1.137000e+05</td>\n      <td>0.125000</td>\n      <td>3.6452</td>\n      <td>27</td>\n      <td>0.250000</td>\n      <td>0.640000</td>\n      <td>-0.000650</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>808</td>\n      <td>816</td>\n      <td>728350</td>\n      <td>728372</td>\n      <td>433</td>\n      <td>20</td>\n      <td>54</td>\n      <td>44478</td>\n      <td>70</td>\n      <td>111</td>\n      <td>...</td>\n      <td>0.000922</td>\n      <td>2.460227</td>\n      <td>3.558240e+06</td>\n      <td>0.002887</td>\n      <td>3.5775</td>\n      <td>41</td>\n      <td>1.082500</td>\n      <td>0.148491</td>\n      <td>-0.000692</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39</td>\n      <td>192</td>\n      <td>2212076</td>\n      <td>2212144</td>\n      <td>11388</td>\n      <td>705</td>\n      <td>420</td>\n      <td>1311391</td>\n      <td>29</td>\n      <td>141</td>\n      <td>...</td>\n      <td>0.000085</td>\n      <td>1.094579</td>\n      <td>5.245564e+07</td>\n      <td>0.000055</td>\n      <td>2.3031</td>\n      <td>112</td>\n      <td>0.022912</td>\n      <td>0.064558</td>\n      <td>-0.000008</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>781</td>\n      <td>789</td>\n      <td>3353146</td>\n      <td>3353173</td>\n      <td>210</td>\n      <td>16</td>\n      <td>29</td>\n      <td>3202</td>\n      <td>114</td>\n      <td>134</td>\n      <td>...</td>\n      <td>0.006246</td>\n      <td>0.972222</td>\n      <td>1.280800e+05</td>\n      <td>0.006219</td>\n      <td>3.6972</td>\n      <td>20</td>\n      <td>0.820312</td>\n      <td>0.249703</td>\n      <td>-0.000191</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1540</td>\n      <td>1560</td>\n      <td>618457</td>\n      <td>618502</td>\n      <td>521</td>\n      <td>72</td>\n      <td>67</td>\n      <td>48231</td>\n      <td>82</td>\n      <td>111</td>\n      <td>...</td>\n      <td>0.000601</td>\n      <td>0.578889</td>\n      <td>1.446930e+07</td>\n      <td>0.002297</td>\n      <td>2.9558</td>\n      <td>29</td>\n      <td>0.100502</td>\n      <td>0.116061</td>\n      <td>-0.000471</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1936</th>\n      <td>249</td>\n      <td>277</td>\n      <td>325780</td>\n      <td>325796</td>\n      <td>273</td>\n      <td>54</td>\n      <td>22</td>\n      <td>35033</td>\n      <td>119</td>\n      <td>141</td>\n      <td>...</td>\n      <td>0.000628</td>\n      <td>0.609375</td>\n      <td>1.401320e+06</td>\n      <td>0.004563</td>\n      <td>2.5946</td>\n      <td>22</td>\n      <td>0.093621</td>\n      <td>0.564050</td>\n      <td>0.000010</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1937</th>\n      <td>144</td>\n      <td>175</td>\n      <td>340581</td>\n      <td>340598</td>\n      <td>287</td>\n      <td>44</td>\n      <td>24</td>\n      <td>34599</td>\n      <td>112</td>\n      <td>133</td>\n      <td>...</td>\n      <td>0.000607</td>\n      <td>0.544592</td>\n      <td>1.383960e+06</td>\n      <td>0.004923</td>\n      <td>2.6513</td>\n      <td>21</td>\n      <td>0.148244</td>\n      <td>0.498264</td>\n      <td>-0.000203</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1938</th>\n      <td>145</td>\n      <td>174</td>\n      <td>386779</td>\n      <td>386794</td>\n      <td>292</td>\n      <td>40</td>\n      <td>22</td>\n      <td>37572</td>\n      <td>120</td>\n      <td>140</td>\n      <td>...</td>\n      <td>0.000532</td>\n      <td>0.671264</td>\n      <td>1.502880e+06</td>\n      <td>0.004818</td>\n      <td>2.4872</td>\n      <td>20</td>\n      <td>0.182500</td>\n      <td>0.603306</td>\n      <td>0.000018</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1939</th>\n      <td>137</td>\n      <td>170</td>\n      <td>422497</td>\n      <td>422528</td>\n      <td>419</td>\n      <td>97</td>\n      <td>47</td>\n      <td>52715</td>\n      <td>117</td>\n      <td>140</td>\n      <td>...</td>\n      <td>0.000436</td>\n      <td>0.409580</td>\n      <td>2.108600e+06</td>\n      <td>0.002386</td>\n      <td>2.7554</td>\n      <td>23</td>\n      <td>0.044532</td>\n      <td>0.189679</td>\n      <td>-0.000041</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1940</th>\n      <td>1261</td>\n      <td>1281</td>\n      <td>87951</td>\n      <td>87967</td>\n      <td>103</td>\n      <td>26</td>\n      <td>22</td>\n      <td>11682</td>\n      <td>101</td>\n      <td>133</td>\n      <td>...</td>\n      <td>0.002739</td>\n      <td>0.321875</td>\n      <td>9.345600e+05</td>\n      <td>0.014529</td>\n      <td>3.1055</td>\n      <td>32</td>\n      <td>0.152367</td>\n      <td>0.212810</td>\n      <td>-0.001106</td>\n      <td>80</td>\n    </tr>\n  </tbody>\n</table>\n<p>21160 rows × 55 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"feat_eng(test)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:48.917606Z","iopub.execute_input":"2024-06-16T16:28:48.917979Z","iopub.status.idle":"2024-06-16T16:28:48.971403Z","shell.execute_reply.started":"2024-06-16T16:28:48.917950Z","shell.execute_reply":"2024-06-16T16:28:48.969955Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"          id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  \\\n0      19219       1015       1033    3826564    3826588           659   \n1      19220       1257       1271     419960     419973           370   \n2      19221       1358       1372     117715     117724           289   \n3      19222        158        168     232415     232440            80   \n4      19223        559        592     544375     544389           140   \n...      ...        ...        ...        ...        ...           ...   \n12809  32028       1101       1116     447943     447992           313   \n12810  32029       1289       1306    3149494    3149542            59   \n12811  32030         41        210    1587535    1587191         16584   \n12812  32031       1329       1340     702237     702267           386   \n12813  32032         39        187    1859616    1859633          5480   \n\n       X_Perimeter  Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n0               23           46              62357                     67   \n1               26           28              39293                     92   \n2               36           32              29386                    101   \n3               10           11               8586                    107   \n4               19           15              15524                    103   \n...            ...          ...                ...                    ...   \n12809           32           37              21603                     79   \n12810            9           18               5249                    113   \n12811          796          522            1858162                     24   \n12812           43           34              36875                     66   \n12813          634          383             582040                     38   \n\n       ...  Luminosity Contrast   Density  Thickness&Luminosity  Edge_Density  \\\n0      ...             0.000962  1.525463          9.353550e+06      0.002375   \n1      ...             0.001018  2.032967          1.571720e+06      0.003355   \n2      ...             0.001123  2.293651          1.175440e+06      0.004671   \n3      ...             0.003843  0.320000          8.586000e+05      0.022500   \n4      ...             0.001997  0.303030          9.314400e+05      0.009824   \n...    ...                  ...       ...                   ...           ...   \n12809  ...             0.001111  0.425850          1.512210e+06      0.004235   \n12810  ...             0.005334  0.072304          2.099600e+05      0.030132   \n12811  ...             0.000064 -0.285262          7.432648e+07      0.000038   \n12812  ...             0.001573  1.169697          1.475000e+06      0.003214   \n12813  ...             0.000177  2.178060          2.328160e+07      0.000116   \n\n       Spatial_Distribution_Index  _Color_Range  _Compactness_X  \\\n0                          3.7793            60        1.245747   \n1                          2.9164            40        0.547337   \n2                          2.5260            33        0.222994   \n3                          4.3991            33        0.800000   \n4                          2.9008            31        0.387812   \n...                           ...           ...             ...   \n12809                      3.1625            24        0.305664   \n12810                      3.3492            28        0.728395   \n12811                      2.3104           119        0.026174   \n12812                      2.5988            58        0.208761   \n12813                      3.2728           103        0.013633   \n\n       _Compactness_Y  _Normalized_Luminosity_Index  _Thickness_Steel_Type  \n0            0.311437                     -0.000343                    150  \n1            0.471939                     -0.000393                     40  \n2            0.282227                     -0.000151                     40  \n3            0.661157                     -0.000922                    100  \n4            0.622222                     -0.000639                     60  \n...               ...                           ...                    ...  \n12809        0.228634                     -0.000993                     70  \n12810        0.182099                     -0.000759                     40  \n12811        0.060862                     -0.000005                     40  \n12812        0.333910                     -0.000681                     40  \n12813        0.037358                     -0.000019                     40  \n\n[12814 rows x 49 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>X_Minimum</th>\n      <th>X_Maximum</th>\n      <th>Y_Minimum</th>\n      <th>Y_Maximum</th>\n      <th>Pixels_Areas</th>\n      <th>X_Perimeter</th>\n      <th>Y_Perimeter</th>\n      <th>Sum_of_Luminosity</th>\n      <th>Minimum_of_Luminosity</th>\n      <th>...</th>\n      <th>Luminosity Contrast</th>\n      <th>Density</th>\n      <th>Thickness&amp;Luminosity</th>\n      <th>Edge_Density</th>\n      <th>Spatial_Distribution_Index</th>\n      <th>_Color_Range</th>\n      <th>_Compactness_X</th>\n      <th>_Compactness_Y</th>\n      <th>_Normalized_Luminosity_Index</th>\n      <th>_Thickness_Steel_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19219</td>\n      <td>1015</td>\n      <td>1033</td>\n      <td>3826564</td>\n      <td>3826588</td>\n      <td>659</td>\n      <td>23</td>\n      <td>46</td>\n      <td>62357</td>\n      <td>67</td>\n      <td>...</td>\n      <td>0.000962</td>\n      <td>1.525463</td>\n      <td>9.353550e+06</td>\n      <td>0.002375</td>\n      <td>3.7793</td>\n      <td>60</td>\n      <td>1.245747</td>\n      <td>0.311437</td>\n      <td>-0.000343</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19220</td>\n      <td>1257</td>\n      <td>1271</td>\n      <td>419960</td>\n      <td>419973</td>\n      <td>370</td>\n      <td>26</td>\n      <td>28</td>\n      <td>39293</td>\n      <td>92</td>\n      <td>...</td>\n      <td>0.001018</td>\n      <td>2.032967</td>\n      <td>1.571720e+06</td>\n      <td>0.003355</td>\n      <td>2.9164</td>\n      <td>40</td>\n      <td>0.547337</td>\n      <td>0.471939</td>\n      <td>-0.000393</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19221</td>\n      <td>1358</td>\n      <td>1372</td>\n      <td>117715</td>\n      <td>117724</td>\n      <td>289</td>\n      <td>36</td>\n      <td>32</td>\n      <td>29386</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0.001123</td>\n      <td>2.293651</td>\n      <td>1.175440e+06</td>\n      <td>0.004671</td>\n      <td>2.5260</td>\n      <td>33</td>\n      <td>0.222994</td>\n      <td>0.282227</td>\n      <td>-0.000151</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19222</td>\n      <td>158</td>\n      <td>168</td>\n      <td>232415</td>\n      <td>232440</td>\n      <td>80</td>\n      <td>10</td>\n      <td>11</td>\n      <td>8586</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0.003843</td>\n      <td>0.320000</td>\n      <td>8.586000e+05</td>\n      <td>0.022500</td>\n      <td>4.3991</td>\n      <td>33</td>\n      <td>0.800000</td>\n      <td>0.661157</td>\n      <td>-0.000922</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19223</td>\n      <td>559</td>\n      <td>592</td>\n      <td>544375</td>\n      <td>544389</td>\n      <td>140</td>\n      <td>19</td>\n      <td>15</td>\n      <td>15524</td>\n      <td>103</td>\n      <td>...</td>\n      <td>0.001997</td>\n      <td>0.303030</td>\n      <td>9.314400e+05</td>\n      <td>0.009824</td>\n      <td>2.9008</td>\n      <td>31</td>\n      <td>0.387812</td>\n      <td>0.622222</td>\n      <td>-0.000639</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12809</th>\n      <td>32028</td>\n      <td>1101</td>\n      <td>1116</td>\n      <td>447943</td>\n      <td>447992</td>\n      <td>313</td>\n      <td>32</td>\n      <td>37</td>\n      <td>21603</td>\n      <td>79</td>\n      <td>...</td>\n      <td>0.001111</td>\n      <td>0.425850</td>\n      <td>1.512210e+06</td>\n      <td>0.004235</td>\n      <td>3.1625</td>\n      <td>24</td>\n      <td>0.305664</td>\n      <td>0.228634</td>\n      <td>-0.000993</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>12810</th>\n      <td>32029</td>\n      <td>1289</td>\n      <td>1306</td>\n      <td>3149494</td>\n      <td>3149542</td>\n      <td>59</td>\n      <td>9</td>\n      <td>18</td>\n      <td>5249</td>\n      <td>113</td>\n      <td>...</td>\n      <td>0.005334</td>\n      <td>0.072304</td>\n      <td>2.099600e+05</td>\n      <td>0.030132</td>\n      <td>3.3492</td>\n      <td>28</td>\n      <td>0.728395</td>\n      <td>0.182099</td>\n      <td>-0.000759</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>12811</th>\n      <td>32030</td>\n      <td>41</td>\n      <td>210</td>\n      <td>1587535</td>\n      <td>1587191</td>\n      <td>16584</td>\n      <td>796</td>\n      <td>522</td>\n      <td>1858162</td>\n      <td>24</td>\n      <td>...</td>\n      <td>0.000064</td>\n      <td>-0.285262</td>\n      <td>7.432648e+07</td>\n      <td>0.000038</td>\n      <td>2.3104</td>\n      <td>119</td>\n      <td>0.026174</td>\n      <td>0.060862</td>\n      <td>-0.000005</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>12812</th>\n      <td>32031</td>\n      <td>1329</td>\n      <td>1340</td>\n      <td>702237</td>\n      <td>702267</td>\n      <td>386</td>\n      <td>43</td>\n      <td>34</td>\n      <td>36875</td>\n      <td>66</td>\n      <td>...</td>\n      <td>0.001573</td>\n      <td>1.169697</td>\n      <td>1.475000e+06</td>\n      <td>0.003214</td>\n      <td>2.5988</td>\n      <td>58</td>\n      <td>0.208761</td>\n      <td>0.333910</td>\n      <td>-0.000681</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>12813</th>\n      <td>32032</td>\n      <td>39</td>\n      <td>187</td>\n      <td>1859616</td>\n      <td>1859633</td>\n      <td>5480</td>\n      <td>634</td>\n      <td>383</td>\n      <td>582040</td>\n      <td>38</td>\n      <td>...</td>\n      <td>0.000177</td>\n      <td>2.178060</td>\n      <td>2.328160e+07</td>\n      <td>0.000116</td>\n      <td>3.2728</td>\n      <td>103</td>\n      <td>0.013633</td>\n      <td>0.037358</td>\n      <td>-0.000019</td>\n      <td>40</td>\n    </tr>\n  </tbody>\n</table>\n<p>12814 rows × 49 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4.分割目标与特征","metadata":{}},{"cell_type":"code","source":"X=train.drop(columns=target_cols,axis=1)\ny=train.loc[:,target_cols]\nX.head()\ny.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:28:53.942305Z","iopub.execute_input":"2024-06-16T16:28:53.942710Z","iopub.status.idle":"2024-06-16T16:28:53.962592Z","shell.execute_reply.started":"2024-06-16T16:28:53.942677Z","shell.execute_reply":"2024-06-16T16:28:53.961085Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n0       0          0         0       1          0      0             0\n1       0          0         0       0          0      0             1\n2       0          0         1       0          0      0             0\n3       0          0         1       0          0      0             0\n4       0          0         0       0          0      0             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pastry</th>\n      <th>Z_Scratch</th>\n      <th>K_Scatch</th>\n      <th>Stains</th>\n      <th>Dirtiness</th>\n      <th>Bumps</th>\n      <th>Other_Faults</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5. 创建DataLoader","metadata":{}},{"cell_type":"code","source":"# 将数据集分割为训练集和验证集，测试集比例为20%\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=17)\n\n# 标准化数据\nstd_scaler=StandardScaler()\nX_train_scaled=std_scaler.fit_transform(X_train)\nX_val_scaled=std_scaler.transform(X_val)\n\n# 创建张量\nX_train_tensor,y_train_tensor=torch.as_tensor(X_train_scaled,dtype=torch.float32),torch.as_tensor(y_train.values,dtype=torch.float32)\nX_val_tensor,y_val_tensor=torch.as_tensor(X_val_scaled,dtype=torch.float32),torch.as_tensor(y_val.values,dtype=torch.float32)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:29:00.295502Z","iopub.execute_input":"2024-06-16T16:29:00.295981Z","iopub.status.idle":"2024-06-16T16:29:00.404235Z","shell.execute_reply.started":"2024-06-16T16:29:00.295940Z","shell.execute_reply":"2024-06-16T16:29:00.402818Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 6. 创建自定义数据类","metadata":{}},{"cell_type":"code","source":"class TabularData(Dataset):\n    def __init__(self,x_tensor,y_tensor):\n        self.x=x_tensor\n        self.y=y_tensor\n\n    def __getitem__(self, index):\n        return (self.x[index],self.y[index])\n    \n    def __len__(self):\n        return len(self.x)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:29:03.049225Z","iopub.execute_input":"2024-06-16T16:29:03.049729Z","iopub.status.idle":"2024-06-16T16:29:03.058253Z","shell.execute_reply.started":"2024-06-16T16:29:03.049688Z","shell.execute_reply":"2024-06-16T16:29:03.056653Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset=TabularData(X_train_tensor,y_train_tensor)\nval_dataset=TabularData(X_val_tensor,y_val_tensor)\n\ntrain_loader=DataLoader(train_dataset,batch_size=256,num_workers=4,pin_memory=True,shuffle=True)\nval_loader=DataLoader(val_dataset,batch_size=256,num_workers=4,pin_memory=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:29:05.840400Z","iopub.execute_input":"2024-06-16T16:29:05.841604Z","iopub.status.idle":"2024-06-16T16:29:05.851031Z","shell.execute_reply.started":"2024-06-16T16:29:05.841556Z","shell.execute_reply":"2024-06-16T16:29:05.849248Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 7. 创建模型训练类","metadata":{}},{"cell_type":"code","source":"class AllShitsHere(object):\n    def __init__(self, model, loss_fn, optimizer, es_patience=5):\n        # 初始化参数\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n        self.model.to(self.device)\n\n        # 初始化将来使用的变量（目前为空）\n        self.train_loader = None\n        self.val_loader = None\n\n        # 用于早停的参数\n        self.patience = es_patience\n        self.min_delta = 0\n        self.counter = 0\n        self.min_validation_loss = float('inf')\n\n        # 内部计算\n        self.losses = []\n        self.val_losses = []\n        self.total_epochs = 0\n        self.scores = []\n        self.val_scores = []\n\n        # 训练和验证步骤函数\n        self.train_step_fn = self._make_train_step_fn()\n        self.val_step_fn = self._make_val_step_fn()\n\n    def _should_early_stop(self, val_loss):\n        if val_loss < self.min_validation_loss:\n            self.min_validation_loss = val_loss\n            counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n    def to(self, device):\n        try:\n            self.device = device\n            self.model.to(self.device)\n        except RuntimeError:\n            self.device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n            print(f\"Can't send to {device}, moving to {self.device} instead!\")\n            self.model.to(self.device)\n\n    def set_loaders(self, train_loader, val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n    def calculate_scores(self, yhat, y):\n        scores_per_epoch = []\n        for i in range(7):\n            try:\n                score = roc_auc_score(y[:, i].detach().cpu().numpy(), yhat[:, i].detach().cpu().numpy(),\n                                      multi_class='ovo', average='weighted')\n                scores_per_epoch.append(score)\n            except ValueError:\n                scores_per_epoch.append(0.5)\n        return np.mean(scores_per_epoch)\n\n    def _make_train_step_fn(self):\n        def perform_train_step_fn(X, y):\n            # 设置模型为训练模式\n            self.model.train()\n            # 前向传播\n            yhat = self.model(X)\n            # 计算得分\n            train_score = self.calculate_scores(yhat, y)\n            # 计算损失\n            loss = self.loss_fn(yhat, y)\n            # 计算梯度\n            loss.backward()\n            # 更新参数\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n            return loss.item(), train_score\n\n        return perform_train_step_fn\n\n    def _make_val_step_fn(self):\n        def perform_val_step(X, y):\n            # 设置模型为评估模式\n            self.model.eval()\n            # 前向传播\n            yhat = self.model(X)\n            # 计算得分\n            val_score = self.calculate_scores(yhat, y)\n            # 计算损失\n            loss = self.loss_fn(yhat, y)\n\n            return loss.item(), val_score\n\n        return perform_val_step\n\n    def _mini_batch(self, validation=False):\n        if validation:\n            data_loader = self.val_loader\n            step_fn = self.val_step_fn\n\n        else:\n            data_loader = self.train_loader\n            step_fn = self.train_step_fn\n\n        if data_loader is None:\n            return None\n\n        mini_batch_losses = []\n        mini_batch_scores = []\n        for X_batch, y_batch in data_loader:\n            X_batch = X_batch.to(self.device)\n            y_batch = y_batch.to(self.device)\n\n            mini_batch_loss, mini_batch_score = step_fn(X_batch, y_batch)\n            mini_batch_losses.append(mini_batch_loss)\n            mini_batch_scores.append(mini_batch_score)\n\n        return np.mean(mini_batch_losses), np.mean(mini_batch_scores)\n\n    def set_seed(self, seed=42):\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n\n    def train(self, n_epochs, seed=42):\n        self.set_seed(seed)\n        for epoch in tqdm(range(n_epochs)):\n            self.total_epochs += 1\n            # 使用小批量进行训练\n            loss, train_score = self._mini_batch(validation=False)\n            self.scores.append(train_score)\n            self.losses.append(loss)\n\n            # 使用小批量进行验证\n            with torch.no_grad():\n                val_loss, val_score = self._mini_batch(validation=True)\n                self.val_losses.append(val_loss)\n                self.val_scores.append(val_score)\n                if self._should_early_stop(val_loss):\n                    print(\"early stopping\")\n                    break\n\n    def predict(self, X):\n        self.model.eval()\n        X_tensor = torch.as_tensor(X, dtype=torch.float32, device=self.device)\n        self.model.train()\n        yhat_tensor = self.model(X_tensor)\n        return yhat_tensor.detach().cpu().numpy()\n\n    def plot_figures(self):\n        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n        axes[0].plot(self.losses, label='training loss', c='b')\n        axes[0].plot(self.val_losses, label='validation loss', c='r')\n        axes[0].set_xlabel(\"Epochs\")\n        axes[0].set_ylabel(\"Losses\")\n\n        axes[1].plot(self.scores, label='training score', c='b')\n        axes[1].plot(self.val_scores, label='validation score', c='r')\n        axes[1].set_xlabel(\"Epochs\")\n        axes[1].set_ylabel(\"AUC-ROC\")\n\n        axes[0].legend()\n        axes[1].legend()\n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:29:10.668837Z","iopub.execute_input":"2024-06-16T16:29:10.669254Z","iopub.status.idle":"2024-06-16T16:29:10.697285Z","shell.execute_reply.started":"2024-06-16T16:29:10.669219Z","shell.execute_reply":"2024-06-16T16:29:10.695852Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 8.创建模型类","metadata":{}},{"cell_type":"code","source":"class TabularNet(nn.Module):\n    def __init__(self,p,input_shape,output_shape):\n        super(TabularNet,self).__init__()\n        self.p=p\n        self.input_shape=input_shape\n        self.output_shape=output_shape\n\n        self.feature_extractor=nn.Sequential(\n            nn.Linear(input_shape,384),\n            nn.BatchNorm1d(384),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(384,1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(1024,128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(128,64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(64,32),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(self.p))\n        \n        self.classifier=nn.Sequential(\n            nn.Linear(32,output_shape),\n            nn.Sigmoid())\n        \n    def forward(self,x):\n        x=self.feature_extractor(x)\n        x=self.classifier(x)\n        return x\n        \n        \n        \n          ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:29:15.366041Z","iopub.execute_input":"2024-06-16T16:29:15.366531Z","iopub.status.idle":"2024-06-16T16:29:15.377819Z","shell.execute_reply.started":"2024-06-16T16:29:15.366491Z","shell.execute_reply":"2024-06-16T16:29:15.376140Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 9.模型训练","metadata":{}},{"cell_type":"code","source":"model=TabularNet(p=0.3,input_shape=48,output_shape=7)\noptimizer=optim.Adam(model.parameters(),lr=0.001)\nloss_fn=nn.BCELoss(reduction='mean')\n\nsummary(model,input_size=(256,48))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:37:21.764907Z","iopub.execute_input":"2024-06-16T16:37:21.766803Z","iopub.status.idle":"2024-06-16T16:37:21.803656Z","shell.execute_reply.started":"2024-06-16T16:37:21.766731Z","shell.execute_reply":"2024-06-16T16:37:21.802260Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nTabularNet                               [256, 7]                  --\n├─Sequential: 1-1                        [256, 32]                 --\n│    └─Linear: 2-1                       [256, 384]                18,816\n│    └─BatchNorm1d: 2-2                  [256, 384]                768\n│    └─ReLU: 2-3                         [256, 384]                --\n│    └─Dropout: 2-4                      [256, 384]                --\n│    └─Linear: 2-5                       [256, 1024]               394,240\n│    └─BatchNorm1d: 2-6                  [256, 1024]               2,048\n│    └─ReLU: 2-7                         [256, 1024]               --\n│    └─Dropout: 2-8                      [256, 1024]               --\n│    └─Linear: 2-9                       [256, 128]                131,200\n│    └─BatchNorm1d: 2-10                 [256, 128]                256\n│    └─ReLU: 2-11                        [256, 128]                --\n│    └─Dropout: 2-12                     [256, 128]                --\n│    └─Linear: 2-13                      [256, 64]                 8,256\n│    └─BatchNorm1d: 2-14                 [256, 64]                 128\n│    └─ReLU: 2-15                        [256, 64]                 --\n│    └─Dropout: 2-16                     [256, 64]                 --\n│    └─Linear: 2-17                      [256, 32]                 2,080\n│    └─BatchNorm1d: 2-18                 [256, 32]                 64\n│    └─ReLU: 2-19                        [256, 32]                 --\n│    └─Dropout: 2-20                     [256, 32]                 --\n├─Sequential: 1-2                        [256, 7]                  --\n│    └─Linear: 2-21                      [256, 7]                  231\n│    └─Sigmoid: 2-22                     [256, 7]                  --\n==========================================================================================\nTotal params: 558,087\nTrainable params: 558,087\nNon-trainable params: 0\nTotal mult-adds (M): 142.87\n==========================================================================================\nInput size (MB): 0.05\nForward/backward pass size (MB): 6.70\nParams size (MB): 2.23\nEstimated Total Size (MB): 8.98\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"AnuwazNet=AllShitsHere(model,loss_fn,optimizer)\nAnuwazNet.set_loaders(train_loader,val_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:39:31.687249Z","iopub.execute_input":"2024-06-16T16:39:31.687721Z","iopub.status.idle":"2024-06-16T16:39:31.697242Z","shell.execute_reply.started":"2024-06-16T16:39:31.687690Z","shell.execute_reply":"2024-06-16T16:39:31.695403Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"AnuwazNet.train(100)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:39:35.192637Z","iopub.execute_input":"2024-06-16T16:39:35.193104Z","iopub.status.idle":"2024-06-16T16:39:42.768425Z","shell.execute_reply.started":"2024-06-16T16:39:35.193068Z","shell.execute_reply":"2024-06-16T16:39:42.766429Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"074bd1204cd54a82a5f15f0945b1e6e2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAnuwazNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[11], line 135\u001b[0m, in \u001b[0;36mAllShitsHere.train\u001b[0;34m(self, n_epochs, seed)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# 使用小批量进行训练\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m loss, train_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores\u001b[38;5;241m.\u001b[39mappend(train_score)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mappend(loss)\n","Cell \u001b[0;32mIn[11], line 118\u001b[0m, in \u001b[0;36mAllShitsHere._mini_batch\u001b[0;34m(self, validation)\u001b[0m\n\u001b[1;32m    115\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    116\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 118\u001b[0m mini_batch_loss, mini_batch_score \u001b[38;5;241m=\u001b[39m \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m mini_batch_losses\u001b[38;5;241m.\u001b[39mappend(mini_batch_loss)\n\u001b[1;32m    120\u001b[0m mini_batch_scores\u001b[38;5;241m.\u001b[39mappend(mini_batch_score)\n","Cell \u001b[0;32mIn[11], line 76\u001b[0m, in \u001b[0;36mAllShitsHere._make_train_step_fn.<locals>.perform_train_step_fn\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(yhat, y)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# 计算梯度\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"AnuwazNet.plot_figures()\nAnuwazNet.val_scores\nAnuwazNet.val_losses.index(min(AnuwazNet.val_losses))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. 预测","metadata":{}},{"cell_type":"code","source":"preds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\nfor i,col in enumerate(target_cols):\n    sample[col]=preds[:,i]\n\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:06:29.581461Z","iopub.execute_input":"2024-03-09T11:06:29.582298Z","iopub.status.idle":"2024-03-09T11:06:29.61857Z","shell.execute_reply.started":"2024-03-09T11:06:29.582241Z","shell.execute_reply":"2024-03-09T11:06:29.617739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.开始制作原型","metadata":{}},{"cell_type":"code","source":"def make_data_loader(X_train,X_val,y_train,y_val):\n\n    # 标准化数据\n    std_scaler=StandardScaler()\n    X_train_scaled=std_scaler.fit_transform(X_train)\n    X_val_scaled=std_scaler.transform(X_val)\n\n     # 创建张量\n    X_train_tensor,y_train_tensor=torch.as_tensor(X_train_scaled,dtype=torch.float32),torch.as_tensor(y_train.values,dtype=torch.float32)\n    X_val_tensor,y_val_tensor=torch.as_tensor(X_val_scaled,dtype=torch.float32),torch.as_tensor(y_val.values,dtype=torch.float32)\n\n    train_dataset=TabularData(X_train_tensor,y_train_tensor)\n    val_dataset=TabularData(X_val_tensor,y_val_tensor)\n\n    train_loader=DataLoader(train_dataset,batch_size=256,num_workers=4,pin_memory=True,shuffle=True)\n    val_loader=DataLoader(val_dataset,batch_size=256,num_workers=4,pin_memory=True)\n\n    return train_loader,val_loader","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:06:29.790896Z","iopub.execute_input":"2024-03-09T11:06:29.79124Z","iopub.status.idle":"2024-03-09T11:06:29.799543Z","shell.execute_reply.started":"2024-03-09T11:06:29.791201Z","shell.execute_reply":"2024-03-09T11:06:29.798588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf=MultilabelStratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n\nall_predictions=[]\nfinal_mean_scores=[]\n# 执行交叉验证\nfor train_idx, val_idx in mskf.split(X,y):\n    X_train,y_train=X.iloc[train_idx],y.iloc[train_idx]\n    X_val,y_val=X.iloc[val_idx],y.iloc[val_idx]\n\n    train_loader,val_loader=make_data_loader(X_train,X_val,y_train,y_val)\n\n    model=TabularNet(p=0.3,input_shape=48,output_shape=7)\n    optimizer=optim.Adam(model.parameters(),lr=3e-4)\n    loss_fn=nn.BCELoss(reduction='mean')\n\n    AnuwazNet=AllShitsHere(model,loss_fn,optimizer)\n    AnuwazNet.set_loaders(train_loader,val_loader)\n    AnuwazNet.train(100)\n    print(f\"Min val loss: {np.min(AnuwazNet.val_losses)}\\tFinal val loss: {np.mean(AnuwazNet.val_losses)}\")\n    preds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\n    all_predictions.append(preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:06:41.866214Z","iopub.execute_input":"2024-03-09T11:06:41.866533Z","iopub.status.idle":"2024-03-09T11:09:00.675703Z","shell.execute_reply.started":"2024-03-09T11:06:41.866505Z","shell.execute_reply":"2024-03-09T11:09:00.674656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output(pred_list):\n    pred_array=np.array(pred_list)\n    pred_array_mean=np.mean(pred_array,axis=0)\n\n    for i,col in enumerate(target_cols):\n        sample[col]=pred_array_mean[:,i]\n\n    return sample\noutput(all_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:00.677396Z","iopub.execute_input":"2024-03-09T11:09:00.677723Z","iopub.status.idle":"2024-03-09T11:09:00.683539Z","shell.execute_reply.started":"2024-03-09T11:09:00.677686Z","shell.execute_reply":"2024-03-09T11:09:00.68247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.优化类","metadata":{}},{"cell_type":"code","source":"class Goodclass(object):\n    def __init__(self, model, loss_fn, optimizer, es_patience=5):\n        # 初始化参数\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n        self.model.to(self.device)\n\n        # 初始化将来使用的变量（目前为空）\n        self.train_loader = None\n        self.val_loader = None\n\n        # 用于早停的参数\n        self.patience = es_patience\n        self.min_delta = 0\n        self.counter = 0\n        self.min_validation_loss = float('inf')\n\n        # 内部计算\n        self.losses = []\n        self.val_losses = []\n        self.total_epochs = 0\n\n        # 训练和验证步骤函数\n        self.train_step_fn = self._make_train_step_fn()\n        self.val_step_fn = self._make_val_step_fn()\n\n    def _should_early_stop(self, val_loss):\n        if val_loss < self.min_validation_loss:\n            self.min_validation_loss = val_loss\n            counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n    def to(self, device):\n        try:\n            self.device = device\n            self.model.to(self.device)\n        except RuntimeError:\n            self.device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n            print(f\"Can't send to {device}, moving to {self.device} instead!\")\n            self.model.to(self.device)\n\n    def set_loaders(self, train_loader, val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n    def _make_train_step_fn(self):\n        def perform_train_step_fn(X, y):\n            # 设置模型为训练模式\n            self.model.train()\n            # 前向传播\n            yhat = self.model(X)\n            # 计算损失\n            loss = self.loss_fn(yhat, y)\n            # 计算梯度\n            loss.backward()\n            # 更新参数\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n\n            return loss.item()\n\n        return perform_train_step_fn\n\n    def _make_val_step_fn(self):\n        def perform_val_step(X, y):\n            # 设置模型为评估模式\n            self.model.eval()\n            # 前向传播\n            yhat = self.model(X)\n            # 计算损失\n            loss = self.loss_fn(yhat, y)\n\n            return loss.item()\n\n        return perform_val_step\n\n    def _mini_batch(self, validation=False):\n        if validation:\n            data_loader = self.val_loader\n            step_fn = self.val_step_fn\n\n        else:\n            data_loader = self.train_loader\n            step_fn = self.train_step_fn\n\n        if data_loader is None:\n            return None\n\n        mini_batch_losses = []\n        mini_batch_scores = []\n        for X_batch, y_batch in data_loader:\n            X_batch = X_batch.to(self.device)\n            y_batch = y_batch.to(self.device)\n\n            mini_batch_loss = step_fn(X_batch, y_batch)\n            mini_batch_losses.append(mini_batch_loss)\n\n        return np.mean(mini_batch_losses)\n\n    def set_seed(self, seed=42):\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n\n    def train(self, n_epochs, seed=42):\n        self.set_seed(seed)\n        for epoch in tqdm(range(n_epochs)):\n            self.total_epochs += 1\n            # 使用小批量进行训练\n            loss = self._mini_batch(validation=False)\n            self.losses.append(loss)\n\n            # 使用小批量进行验证\n            with torch.no_grad():\n                val_loss = self._mini_batch(validation=True)\n                self.val_losses.append(val_loss)\n                if self._should_early_stop(val_loss):\n                    print(\"early stopping\")\n                    break\n\n    def predict(self, X):\n        self.model.eval()\n        X_tensor = torch.as_tensor(X, dtype=torch.float32, device=self.device)\n        yhat_tensor = self.model(X_tensor)\n        self.model.train()\n        return yhat_tensor.detach().cpu().numpy()\n\n    def plot_figures(self):\n        fig, ax = plt.subplots(figsize=(10, 4))\n        ax.plot(self.losses, label='training loss', c='b')\n        ax.plot(self.val_losses, label='validation loss', c='r')\n        ax.set_xlabel(\"Epochs\")\n        ax.set_ylabel(\"Losses\")\n        ax.legend()\n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:00.718877Z","iopub.execute_input":"2024-03-09T11:09:00.719125Z","iopub.status.idle":"2024-03-09T11:09:00.745703Z","shell.execute_reply.started":"2024-03-09T11:09:00.719103Z","shell.execute_reply":"2024-03-09T11:09:00.744939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=TabularNet(p=0.3,input_shape=48,output_shape=7)\noptimizer=optim.Adam(model.parameters(),lr=0.001)\nloss_fn=nn.BCELoss(reduction='mean')\nAnuwazNet=Goodclass(model,loss_fn,optimizer)\nAnuwazNet.set_loaders(train_loader,val_loader)\nAnuwazNet.train(100)\nAnuwazNet.val_losses\nAnuwazNet.plot_figures()\npreds=AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id'])))\n\ndef output_single(preds):\n\n    for i,col in enumerate(target_cols):\n        sample[col]=preds[:,i]\n\n    return sample\n\noutput_single(preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:00.746675Z","iopub.execute_input":"2024-03-09T11:09:00.746943Z","iopub.status.idle":"2024-03-09T11:09:00.767028Z","shell.execute_reply.started":"2024-03-09T11:09:00.74692Z","shell.execute_reply":"2024-03-09T11:09:00.766301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 13.找到LR范围\n","metadata":{}},{"cell_type":"code","source":"from torch_lr_finder import LRFinder\ntorch.manual_seed(11)\nmodel=TabularNet(p=0.3,input_shape=48,output_shape=7)\noptimizer=optim.Adam(model.parameters(),lr=3e-4)\nloss_fn=nn.BCELoss(reduction='mean')\ndevice=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nlr_finder=LRFinder(model,optimizer,loss_fn,device)\nlr_finder.range_test(train_loader,end_lr=0.1,num_iter=100)\nlr_finder.plot(log_lr=True)\nlr_finder.reset()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:29.706325Z","iopub.execute_input":"2024-03-09T11:09:29.706642Z","iopub.status.idle":"2024-03-09T11:09:31.121327Z","shell.execute_reply.started":"2024-03-09T11:09:29.706612Z","shell.execute_reply":"2024-03-09T11:09:31.120477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 14.创建更深层模型","metadata":{}},{"cell_type":"code","source":"class TabularNetDeep(nn.Module):\n    def __init__(self,p,input_shape,output_shape):\n        super(TabularNetDeep,self).__init__()\n        self.p=p\n        self.input_shape=input_shape\n        self.output_shape=output_shape\n\n        self.feature_extractor=nn.Sequential(\n            nn.Linear(input_shape,512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(512,1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(1024,4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(4096,1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(1024,256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(256,64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(self.p),\n            \n            nn.Linear(64,48),\n            nn.BatchNorm1d(48),\n            nn.ReLU(),\n            nn.Dropout(self.p))\n        \n        self.classifier=nn.Sequential(\n            nn.Linear(48,output_shape),\n            nn.Sigmoid())\n        \n    def forward(self,x):\n        x=self.feature_extractor(x)\n        x=self.classifier(x)\n        return x\n        \n        \n        \n          ","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:31.123042Z","iopub.execute_input":"2024-03-09T11:09:31.123455Z","iopub.status.idle":"2024-03-09T11:09:31.1346Z","shell.execute_reply.started":"2024-03-09T11:09:31.123401Z","shell.execute_reply":"2024-03-09T11:09:31.133599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 15.OOF预测","metadata":{}},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n\ndef mean_loss():\n    mean_val_losses = []\n    oof_preds = []\n    # 执行交叉验证\n    for train_idx, val_idx in mskf.split(X, y):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n\n        train_loader, val_loader = make_data_loader(X_train, X_val, y_train, y_val)\n        model = TabularNetDeep(p=0.3, input_shape=48, output_shape=7)\n        optimizer = optim.Adam(model.parameters(), lr=1.01e-2)\n        scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n        loss_fn = nn.BCELoss(reduction='mean')\n\n        AnuwazNet = Goodclass(model, loss_fn, optimizer, es_patience=20)\n        AnuwazNet.set_loaders(train_loader, val_loader)\n        AnuwazNet.train(100)\n        print(f\"Min val loss: {np.min(AnuwazNet.val_losses)}\\tFinal val loss: {AnuwazNet.val_losses[-1]}\")\n        mean_val_losses.append(AnuwazNet.val_losses[-3:])\n        oof_preds.append(AnuwazNet.predict(std_scaler.transform(test.drop(columns=['id']))))\n\n    return np.mean(mean_val_losses), oof_preds\n\nmean_validation_losses,oof_predictions=mean_loss()\nmean_validation_losses\ndef output_single(preds):\n    preds_arr=np.array(preds)\n    preds_arr_mean=np.mean(preds_arr,axis=0)\n    for i,col in enumerate(target_cols):\n        sample[col]=preds_arr_mean[:,i]\n\n    return sample\n\noutput_single(oof_predictions)\noutput_single(oof_predictions).to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-09T11:09:31.135972Z","iopub.execute_input":"2024-03-09T11:09:31.136695Z","iopub.status.idle":"2024-03-09T11:09:31.14578Z","shell.execute_reply.started":"2024-03-09T11:09:31.136669Z","shell.execute_reply":"2024-03-09T11:09:31.145014Z"},"trusted":true},"execution_count":null,"outputs":[]}]}